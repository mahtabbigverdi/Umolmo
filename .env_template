# check if symbolic links exist, if not create them
# BLOB_DIR=/datadrive_a/linjie/blob/vigstandard_data_2/linjli/debug_output/UW

# [ -L ./pretrained ] || ln -s ${BLOB_DIR}/mahtab/Umolmo/pretrained/ ./pretrained
# [ -L ./checkpoints ] || ln -s ${BLOB_DIR}/mahtab/Umolmo/checkpoints/ ./checkpoints
# [ -L ./predictions ] || ln -s ${BLOB_DIR}/mahtab/Umolmo/predictions/ ./predictions
# [ -L ./Data ] || ln -s ${BLOB_DIR}/mahtab/Umolmo/Data/ ./Data
# [ -L ./mahtab ] || ln -s ${BLOB_DIR}/mahtab/ ./mahtab
export AZFUSE_CLOUD_FUSE_CONFIG_FILE=./aux_data/configs/azfuse.yaml
export AZFUSE_USE_FUSE=1
export MOLMO_DATA_DIR=./Data
export HF_HOME=/datadrive_a/linjie/blob/vigstandard_data_2/xiyin1wu2_maskrcnn/data/models/
export OUTPUT_DIR=./checkpoints
#export current path to PYTHONPATH
export PYTHONPATH=$(pwd):$PYTHONPATH

export WANDB_API_KEY=""
export HF_ACCESS_TOKEN=""
export WANDB_TEAM="umolmo"
export WANDB_PROJECT="mmseek"
export OLMO_TURNON_TMP_FILE=0
export MOLMO_CACHE_DIR=""
export PRECISION="amp_fp16"

# export NCCL_TIMEOUT_MINUTES=90
export NCCL_DEBUG=INFO
export TORCH_DISTRIBUTED_DEBUG=INFO
export NCCL_P2P_DISABLE=1
export NCCL_SOCKET_IFNAME=lo
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True 
export NCCL_TIMEOUT=3000
export OMP_NUM_THREADS=8
export TORCH_LOGS_RANK0="recompiles,graph_breaks"